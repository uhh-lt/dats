services:
  postgres:
    image: "postgres:15-alpine"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-datsuser}"]
      interval: 30s
      timeout: 10s
      retries: 5
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-datsuser}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-dats123}
    ports:
      - "${POSTGRES_EXPOSED:-13122}:5432"
    volumes:
      - "postgres_data_demo:/var/lib/postgresql/data"
    networks:
      - dats_demo_network

  rabbitmq:
    image: "rabbitmq:3-management-alpine"
    healthcheck:
      test: "rabbitmq-diagnostics check_port_connectivity"
      interval: 30s
      timeout: 10s
      retries: 5
    environment:
      RABBITMQ_DEFAULT_USER: ${RABBITMQ_USER:-datsuser}
      RABBITMQ_DEFAULT_PASS: ${RABBITMQ_PASSWORD:-dats123}
    ports:
      - "${RABBIT_EXPOSED:-13123}:5672"
    volumes:
      - "rabbitmq_data_demo:/var/lib/rabbitmq/data"
    networks:
      - dats_demo_network

  redis:
    image: "redis:7-alpine"
    healthcheck:
      test: ["CMD-SHELL", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 5
    environment:
      REDIS_PASSWORD: ${REDIS_PASSWORD:-dats123}
    ports:
      - "${REDIS_EXPOSED:-13124}:6379"
    volumes:
      - "redis_data_demo:/var/lib/redis/data"
    command: redis-server --requirepass "${REDIS_PASSWORD:-dats123}" --save 60 1
    networks:
      - dats_demo_network

  weaviate:
    command:
      - --host
      - 0.0.0.0
      - --port
      - "8080"
      - --scheme
      - http
    image: semitechnologies/weaviate:1.21.3
    healthcheck:
      test: ["CMD-SHELL", "wget -q --spider http://localhost:8080/v1/.well-known/ready || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
    ports:
      - "${WEAVIATE_EXPOSED:-13132}:8080"
    volumes:
      - "weaviate_data_demo:/var/lib/weaviate"
    restart: on-failure:0
    environment:
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: "true"
      PERSISTENCE_DATA_PATH: "/var/lib/weaviate"
      DEFAULT_VECTORIZER_MODULE: "none"
      CLUSTER_HOSTNAME: "node1"
      LOG_LEVEL: "info"
    networks:
      - dats_demo_network

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.1
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
    environment:
      # see https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-network.html
      # use 127.0.0.1 to access the ES node from OUTSIDE of the docker network (e.g. when ssh tunneling to ltdocker)
      # network.publish_host=127.0.0.1
      # http.publish_port=${ELASTICSEARCH_EXPOSED_PORT:-9200}
      - xpack.security.enabled=false # no auth
      - discovery.type=single-node # single node cluster
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    volumes:
      - elasticsearch_data_demo:/usr/share/elasticsearch/data
      - ./elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml
    ports:
      - "${ELASTICSEARCH_EXPOSED:-13125}:9200"
    networks:
      - dats_demo_network

  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.1
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:5601 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
    ports:
      - "${KIBANA_EXPOSED:-13126}:5601"
    environment:
      ELASTICSEARCH_URL: http://elasticsearch:9200
      ELASTICSEARCH_HOSTS: '["http://elasticsearch:9200"]'
    networks:
      - dats_demo_network
    depends_on:
      elasticsearch:
        condition: service_healthy
        restart: true

  lighttpd:
    image: sebp/lighttpd
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
    volumes:
      - ./backend_repo:/var/www/localhost/htdocs
    ports:
      - "${CONTENT_SERVER_EXPOSED:-13121}:80"
    tty: true
    networks:
      - dats_demo_network
    profiles:
      - dev_frontend

  ray:
    image: uhhlt/dats_ray:${DATS_RAY_DOCKER_VERSION:-debian_dev_latest}
    build:
      context: ../backend/src/app/preprocessing/ray_model_worker
      dockerfile: Dockerfile
    healthcheck:
      test: ["CMD-SHELL", "python /dats_code_ray/check_ray_health.py"]
      start_period: 60s
      interval: 60s
      timeout: 10s
      retries: 5
    command: /dats_code_ray/ray_model_worker_entrypoint.sh
    user: ${UID:-1000}:${GID:-1000}
    environment:
      DATS_BACKEND_CONFIG: /dats_code/src/configs/production.yaml
      LOG_LEVEL: ${LOG_LEVEL:-info}
      RAY_CONFIG: ${RAY_CONFIG:-config_gpu.yaml}
      HUGGINGFACE_HUB_CACHE: /models_cache
      TRANSFORMERS_CACHE: /models_cache
      TORCH_HOME: /models_cache
      NUMBA_CACHE_DIR: /numba_cache
    volumes:
      - ../backend/src/app/preprocessing/ray_model_worker:/dats_code_ray
      - ./spacy_models:/spacy_models
      - ./backend_repo:/tmp/dats
      - ./models_cache:/models_cache
      - ./numba_cache:/numba_cache
    ports:
      - "${RAY_API_EXPOSED:-13130}:8000"
      - "${RAY_DASHBOARD_EXPOSED:-13131}:8265"
    restart: always
    shm_size: 12gb
    networks:
      - dats_demo_network
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["1"]
              capabilities: [gpu]
    profiles:
      - ray

  celery-background-jobs-worker:
    image: uhhlt/dats_backend:${DATS_BACKEND_DOCKER_VERSION:-debian_dev_latest}
    build:
      context: ../backend
      dockerfile: Dockerfile
    healthcheck:
      test: "/opt/envs/dats/bin/python -m celery -A app.celery.celery_worker inspect ping | grep -q pong || exit 1"
      interval: 30s
      timeout: 10s
      retries: 5
    command: /dats_code/src/celery_background_jobs_worker_entrypoint.sh
    user: ${UID:-1000}:${GID:-1000}
    environment:
      DATS_BACKEND_CONFIG: /dats_code/src/configs/production.yaml
      LOG_LEVEL: ${CELERY_LOG_LEVEL:-info}
      INSTALL_JUPYTER: ${CELERY_INSTALL_JUPYTER:-false}
      CELERY_BACKGROUND_JOBS_WORKER_CONCURRENCY: ${CELERY_BACKGROUND_JOBS_WORKER_CONCURRENCY:-1}
      CELERY_DEBUG_MODE: ${CELERY_DEBUG_MODE:-0}
      POSTGRES_DB: ${POSTGRES_DB:-dats}
      POSTGRES_USER: ${POSTGRES_USER:-datsuser}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-dats123}
      RABBITMQ_USER: ${RABBITMQ_USER:-datsuser}
      RABBITMQ_PASSWORD: ${RABBITMQ_PASSWORD:-dats123}
      REDIS_PASSWORD: ${REDIS_PASSWORD:-dats123}
      ES_MIN_HEALTH: ${ES_MIN_HEALTH:-75}
      RAY_ENABLED: ${RAY_ENABLED:-True}
      RAY_HOST: ${RAY_HOST:-ray}
      RAY_PORT: ${RAY_PORT:-8000}
      RAY_PROTOCOL: ${RAY_PROTOCOL:-http}
      OLLAMA_ENABLED: ${OLLAMA_ENABLED:-True}
      OLLAMA_HOST: ${OLLAMA_HOST:-ollama}
      OLLAMA_PORT: ${OLLAMA_PORT:-11434}
      OLLAMA_MODEL: ${OLLAMA_MODEL:-gemma2:9b-instruct-fp16}
      HUGGINGFACE_HUB_CACHE: /models_cache
      TRANSFORMERS_CACHE: /models_cache
      TORCH_HOME: /models_cache
      NUMBA_CACHE_DIR: /numba_cache
    volumes:
      - ../backend/src:/dats_code/src
      - ./backend_repo:/tmp/dats
      - ./models_cache:/models_cache
      - ./numba_cache:/numba_cache
    depends_on:
      postgres:
        condition: service_healthy
        restart: true
      rabbitmq:
        condition: service_healthy
        restart: true
      redis:
        condition: service_healthy
        restart: true
      weaviate:
        condition: service_healthy
        restart: true
      elasticsearch:
        condition: service_healthy
        restart: true
      ray:
        condition: service_healthy
        restart: true
    ports:
      - "${JUPYTER_CELERY_EXPOSED:-13129}:8888"
      - "${CELERY_DEBUG_PORT:-45678}:6900"
    restart: always
    networks:
      - dats_demo_network
      - ollama_network
    profiles:
      - background

  dats-backend-api:
    image: uhhlt/dats_backend:${DATS_BACKEND_DOCKER_VERSION:-debian_dev_latest}
    build:
      context: ../backend
      dockerfile: Dockerfile
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:5500 || exit 1"]
      start_period: 60s
      interval: 60s
      timeout: 10s
      retries: 5
    command: /dats_code/src/backend_api_entrypoint.sh
    user: ${UID:-1000}:${GID:-1000}
    environment:
      DATS_BACKEND_CONFIG: /dats_code/src/configs/production.yaml
      LOG_LEVEL: ${API_LOG_LEVEL:-info}
      INSTALL_JUPYTER: ${API_INSTALL_JUPYTER:-false}
      API_PRODUCTION_MODE: ${API_PRODUCTION_MODE:-0}
      API_PRODUCTION_WORKERS: ${API_PRODUCTION_WORKERS:-10}
      JWT_SECRET: ${JWT_SECRET:-""}
      SYSTEM_USER_EMAIL: ${SYSTEM_USER_EMAIL}
      SYSTEM_USER_PASSWORD: ${SYSTEM_USER_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB:-dats}
      POSTGRES_USER: ${POSTGRES_USER:-datsuser}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-dats123}
      RABBITMQ_USER: ${RABBITMQ_USER:-datsuser}
      RABBITMQ_PASSWORD: ${RABBITMQ_PASSWORD:-dats123}
      REDIS_PASSWORD: ${REDIS_PASSWORD:-dats123}
      ES_MIN_HEALTH: ${ES_MIN_HEALTH:-75}
      RAY_ENABLED: ${RAY_ENABLED:-True}
      RAY_HOST: ${RAY_HOST:-ray}
      RAY_PORT: ${RAY_PORT:-8000}
      RAY_PROTOCOL: ${RAY_PROTOCOL:-http}
      OLLAMA_ENABLED: ${OLLAMA_ENABLED:-True}
      OLLAMA_HOST: ${OLLAMA_HOST:-ollama}
      OLLAMA_PORT: ${OLLAMA_PORT:-11434}
      OLLAMA_MODEL: ${OLLAMA_MODEL:-gemma2:9b-instruct-fp16}
    volumes:
      - ../backend/src:/dats_code/src
      - ./backend_repo:/tmp/dats
    depends_on:
      postgres:
        condition: service_healthy
        restart: true
      rabbitmq:
        condition: service_healthy
        restart: true
      redis:
        condition: service_healthy
        restart: true
      weaviate:
        condition: service_healthy
        restart: true
      elasticsearch:
        condition: service_healthy
        restart: true
      ray:
        condition: service_healthy
        restart: true
      celery-background-jobs-worker:
        condition: service_healthy
        restart: true
    ports:
      - "${API_EXPOSED:-13120}:5500"
      - "${JUPYTER_API_EXPOSED:-13127}:8888"
    restart: always
    networks:
      - dats_demo_network
      - ollama_network
    profiles:
      - backend

  dats-frontend:
    image: uhhlt/dats_frontend:${DATS_FRONTEND_DOCKER_VERSION:-latest}
    build:
      context: ../frontend
      dockerfile: Dockerfile
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:3000 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./backend_repo:/usr/share/nginx/content:ro
    depends_on:
      dats-backend-api:
        condition: service_healthy
        restart: true
    ports:
      - "${FRONTEND_EXPOSED:-13100}:3000"
    networks:
      - dats_demo_network
    profiles:
      - frontend

volumes:
  rabbitmq_data_demo:
    driver: local
  redis_data_demo:
    driver: local
  postgres_data_demo:
    driver: local
  elasticsearch_data_demo:
    driver: local
  weaviate_data_demo:
    driver: local

networks:
  dats_demo_network:
  ollama_network:
    name: ollama_network
    external: true
