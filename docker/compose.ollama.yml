# docker compose -f compose.ollama.yml up -d

services:
  ollama:
    image: ollama/ollama:0.6.0
    ports:
      - ${OLLAMA_EXPOSED:-13133}:11434
    environment:
      - OLLAMA_KEEP_ALIVE=-1
      - OLLAMA_FLASH_ATTENTION=1
      - OLLAMA_MAX_LOADED_MODELS=2
      - OLLAMA_KV_CACHE_TYPE=fp16
    tty: true
    restart: unless-stopped
    volumes:
      - ./ollama_cache:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: [ "${OLLAMA_DEVICE_IDS:-1}" ]
              capabilities: [ gpu ]
    networks:
      - ollama_network

networks:
  ollama_network:
    name: ollama_network
