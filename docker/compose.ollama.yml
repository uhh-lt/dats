# docker compose -f compose.ollama.yml up -d

services:
  ollama:
    image: ollama/ollama:0.9.0
    ports:
      - ${OLLAMA_EXPOSED?ollama-exposed-required!}:11434
    environment:
      - OLLAMA_KEEP_ALIVE=-1
      - OLLAMA_FLASH_ATTENTION=1
      - OLLAMA_MAX_LOADED_MODELS=2
      - OLLAMA_KV_CACHE_TYPE=fp16
    tty: true
    restart: unless-stopped
    volumes:
      - ./ollama_cache:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["${OLLAMA_DEVICE_IDS?ollama-device-ids-required!}"]
              capabilities: [gpu]
    networks:
      - ollama_network

networks:
  ollama_network:
    name: ollama_network
