services:
  ray:
    env_file: ".env.ray-only"
    image: uhhlt/dats_ray:${DATS_RAY_DOCKER_VERSION}
    command: /dats_code_ray/ray_model_worker_entrypoint.sh
    user: ${UID:-1004}:${GID:-1004}
    environment:
      LOG_LEVEL: ${LOG_LEVEL:-info}
      DATS_BACKEND_CONFIG: ${DATS_BACKEND_CONFIG:-/dats_code/src/configs/production.yaml}
      HUGGINGFACE_HUB_CACHE: /models_cache
      TRANSFORMERS_CACHE: /models_cache
      TORCH_HOME: /models_cache
      RAY_PROCESSING_DEVICE_SPACY: ${RAY_PROCESSING_DEVICE_SPACY}
      RAY_PROCESSING_DEVICE_WHISPER: ${RAY_PROCESSING_DEVICE_WHISPER}
      RAY_PROCESSING_DEVICE_DETR: ${RAY_PROCESSING_DEVICE_DETR}
      RAY_PROCESSING_DEVICE_VIT_GPT2: ${RAY_PROCESSING_DEVICE_VIT_GPT2}
      RAY_PROCESSING_DEVICE_BLIP2: ${RAY_PROCESSING_DEVICE_BLIP2}
      RAY_PROCESSING_DEVICE_CLIP: ${RAY_PROCESSING_DEVICE_CLIP}
      RAY_PROCESSING_DEVICE_COTA: ${RAY_PROCESSING_DEVICE_COTA}
      RAY_BLIP2_PRECISION_BIT: ${RAY_BLIP2_PRECISION_BIT:-32}
      NUMBA_CACHE_DIR: /numba_cache
    volumes:
      #      - ../backend/src/app/preprocessing/ray_model_worker:/dats_code_ray
      - ./spacy_models:/spacy_models
      - ./backend_repo:/tmp/dats
      - ./models_cache:/models_cache
      - ./numba_cache:/numba_cache
    ports:
      - "${RAY_API_EXPOSED:-8000}:8000"
      - "${RAY_DASHBOARD_EXPOSED:-8265}:8265"
    restart: always
    shm_size: 12gb
    networks:
      - dats_demo_network
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["${RAY_GPU_DEVICE_IDS:-0}"]
              capabilities: [gpu]
networks:
  dats_demo_network:
