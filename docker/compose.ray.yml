# docker compose -f compose.ray.yml up -d

services:
  ray:
    image: uhhlt/dats_ray:${DATS_RAY_DOCKER_VERSION?dats-ray-docker-version-required!}
    ports:
      - ${RAY_API_EXPOSED?ray-api-exposed-required!}:8000
      - ${RAY_DASHBOARD_EXPOSED?ray-dashboard-exposed-required!}:8265
    build:
      context: ../ray
      dockerfile: Dockerfile
    healthcheck:
      test: ["CMD-SHELL", "python /ray_code/src/check_health.py"]
      start_period: 60s
      interval: 60s
      timeout: 60s
      retries: 20
    command: /ray_code/src/ray_entrypoint.sh
    user: ${DOCKER_UID:-1000}:${DOCKER_GID:-100}
    environment:
      LOG_LEVEL: ${RAY_LOG_LEVEL?ray-log-level-required!}
      SPACY_MODELS_DIR: /ray_cache/spacy_models
      HUGGINGFACE_HUB_CACHE: /ray_cache/hf_hub_cache
      HF_HOME: /ray_cache/hf_cache
      TORCH_HOME: /ray_cache/torch_cache
      NUMBA_CACHE_DIR: /ray_cache/numba_cache
      TORCHINDUCTOR_CACHE_DIR: /ray_cache/torch_inductor_cache
      TRITON_CACHE_DIR: /ray_cache/triton_cache
      CUPY_CACHE_DIR: /ray_cache/cupy_cache
      UV_CACHE_DIR: /ray_cache/uv_cache
      EASYOCR_MODULE_PATH: /ray_cache/EasyOCR
    volumes:
      # - ../ray:/ray_code # uncomment for dev
      - "${RAY_CACHE_DIR:-./ray_cache}:/ray_cache"
    shm_size: 12gb
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["${RAY_DEVICE_IDS?ray-device-ids-required!}"]
              capabilities: [gpu]
    networks:
      - ray_network

networks:
  ray_network:
    name: ray_network
